from __future__ import print_function, absolute_import
from collections import OrderedDict
import torch
import torch.nn.functional as F
from reid.feature_extraction import extract_cnn_feature
from tqdm import tqdm
from sklearn.cluster import AgglomerativeClustering
import numpy as np
from .rerank import re_ranking
import math
import random
import time

def to_numpy(tensor):
    if torch.is_tensor(tensor):
        return tensor.cpu().numpy()
    elif type(tensor).__module__ != 'numpy':
        raise ValueError("Cannot convert {} to numpy array"
                         .format(type(tensor)))
    return tensor


def extract_features_per_cam(model, data_loader):
    model.eval()
    per_cam_features = {}
    per_cam_fname = {}
    print("Start extract features per camera")
    for imgs, fnames, _, camid in tqdm(data_loader):
        camid = list(camid)
        for cam in camid:
            cam = cam.item()
            if cam not in per_cam_features.keys():
                per_cam_features[cam] = []
                per_cam_fname[cam] = []
        with torch.no_grad():
            outputs = extract_cnn_feature(model, imgs)

        for fname, output, cam in zip(fnames, outputs, camid):
            cam = cam.item()
            per_cam_features[cam].append(output)
            per_cam_fname[cam].append(fname)
    return per_cam_features, per_cam_fname


def extract_features_cross_cam(model, data_loader):
    model.eval()
    cross_cam_features = []
    cross_cam_fnames = []
    cross_cam_distribute = []
    cams = []
    cam_number = len(model.classifier)
    print("Start extract features cross camera")
    for imgs, fnames, _, camid in tqdm(data_loader):

        with torch.no_grad():
            outputs = extract_cnn_feature(model, imgs, norm=False)
            fnorm = torch.norm(outputs, p=2, dim=1, keepdim=True)
            norm_outputs = outputs.div(fnorm.expand_as(outputs))
            for i in range(cam_number):

                x = model.classifier[i](outputs)
                if i == 0:
                    distribute = F.softmax(x.data, dim=1)
                else:
                    distribute_tmp = F.softmax(x.data, dim=1)
                    distribute = torch.cat((distribute, distribute_tmp), dim=1)

        for fname, output, cam, dis in zip(fnames, norm_outputs, camid,
                                           distribute):
            cam = cam.item()
            cross_cam_fnames.append(fname)
            cross_cam_features.append(output)
            cams.append(cam)
            cross_cam_distribute.append(dis.cpu().numpy())
    return cross_cam_features, cross_cam_fnames, cross_cam_distribute, cams


def jaccard_sim_cross_cam(cross_cam_distribute):
    print("Start calculate jaccard similarity cross camera, this step may cost a lot of time")
    n = cross_cam_distribute.size(0)
    jaccard_sim = torch.zeros((n, n))
    for i in range(n):
        distribute = cross_cam_distribute[i]
        abs_sub = torch.abs(distribute - cross_cam_distribute)
        sum_distribute = distribute + cross_cam_distribute
        intersection = (sum_distribute - abs_sub).sum(dim=1) / 2
        union = (sum_distribute + abs_sub).sum(dim=1) / 2
        jaccard_sim[i, :] = intersection / union
    return to_numpy(jaccard_sim)


def cluster_cross_cam(cross_cam_dist,
                      cross_cam_fname,
                      eph,
                      linkage="average",
                      cams=None,
                      mix_rate=0.,
                      jaccard_sim=None):
    cluster_results = OrderedDict()
    print("Start cluster cross camera according to distance")
    if mix_rate > 0:
        assert jaccard_sim is not None, "if mix_rate > 0, the jaccard sim is needed"
        assert cams is not None, "if mix_rate > 0, the cam is needed"
        n = len(cross_cam_fname)
        cams = np.array(cams).reshape((n, 1))
        expand_cams = np.tile(cams, n)
        mask = np.array(expand_cams != expand_cams.T, dtype=np.float32)
        cross_cam_dist -= mask * jaccard_sim * mix_rate
    t1 = time.time()
    cross_cam_dist = re_ranking(cross_cam_dist)
    t2 = time.time()
    t_rerank = t2-t1
    print("rerankingæ—¶é—´ä¸º{}".format(t_rerank))
    tri_mat = np.triu(cross_cam_dist, 1)
    tri_mat = tri_mat[np.nonzero(tri_mat)]
    tri_mat = np.sort(tri_mat, axis=None)
    top_num = np.round(eph * tri_mat.size).astype(int)
    eps = tri_mat[top_num]
    print(eps)

    Ag = AgglomerativeClustering(n_clusters=None,
                                 affinity="precomputed",
                                 linkage=linkage,
                                 distance_threshold=eps)
    labels = Ag.fit_predict(cross_cam_dist)
    print(len(set(labels)))
    for fname, label in zip(cross_cam_fname, labels):
        cluster_results[fname] = label
    return cluster_results


def distance_cross_cam(features, use_cpu=False):
    print("Start calculate pairwise distance cross camera")
    n = len(features)
    x = torch.cat(features)
    x = x.view(n, -1)
    if use_cpu:
        dist = 1 - np.matmul(x.cpu().numpy(), x.cpu().numpy().T)
    else:
        dist = 1 - torch.mm(x, x.t())

    return to_numpy(dist)


def distane_per_cam(per_cam_features):
    per_cam_dist = {}
    print("Start calculate pairwise distance per camera")
    for k, features in per_cam_features.items():
        n = len(features)
        x = torch.cat(features)
        x = x.view(n, -1)

        per_cam_dist[k] = 1 - torch.mm(x, x.t())
    return per_cam_dist


def cluster_per_cam(per_cam_dist,
                    per_cam_fname,
                    eph,
                    linkage="average"):
    cluster_results = {}
    print("Start cluster per camera according to distance")
    for k, dist in per_cam_dist.items():
        cluster_results[k] = OrderedDict()

        # handle the number of samples is small
        dist = dist.cpu().numpy()
        n = dist.shape[0]
        if n < eph:
            eph = n // 2
            # double the number of samples
            dist = np.tile(dist, (2, 2))
            per_cam_fname[k] = per_cam_fname[k] + per_cam_fname[k]

        dist = re_ranking(dist)
        tri_mat = np.triu(dist, 1)
        tri_mat = tri_mat[np.nonzero(tri_mat)]
        tri_mat = np.sort(tri_mat, axis=None)
        top_num = np.round(eph * tri_mat.size).astype(int)
        eps = tri_mat[top_num]
        print(eps)

        Ag = AgglomerativeClustering(n_clusters=None,
                                     affinity="precomputed",
                                     linkage=linkage,
                                     distance_threshold=eps)
        labels = Ag.fit_predict(dist)
        print(len(set(labels)))
        for fname, label in zip(per_cam_fname[k], labels):
            cluster_results[k][fname] = label
    return cluster_results



def merge_list(L):
    lenth = len(L)
    for i in range(1, lenth):
        for j in range(i):
            if L[i]=={0}or L[j]=={0}:
                continue
            x = L[i].union(L[j])
            y = len(L[i])+len(L[j])
            if len(x)<y:
                L[i] = x
                L[j] = {0}
    return [i for i in L if i !={0}]



##ğŸ“šğŸ“š
def cluster_per_cam_zmh(per_cam_dist,
                        per_cam_fname,
                        eph,
                        linkage="average"):
    cluster_results = {}
    print("Start cluster per camera according to distance")
    for k, dist in per_cam_dist.items():
        cluster_results[k] = OrderedDict()

        # handle the number of samples is small
        dist = dist.cpu().numpy()
        n = dist.shape[0]
        if n < eph:
            eph = n // 2
            # double the number of samples
            dist = np.tile(dist, (2, 2))
            per_cam_fname[k] = per_cam_fname[k] + per_cam_fname[k]
        cosine_dist = dist
        
        
        dist = re_ranking(dist)
        tri_mat = np.triu(dist, 1)
        tri_mat = tri_mat[np.nonzero(tri_mat)]
        tri_mat = np.sort(tri_mat, axis=None)
        top_num = np.round(eph * tri_mat.size).astype(int)
        eps = tri_mat[top_num]
        print(eps)
        resdist = dist + cosine_dist
        

        Ag = AgglomerativeClustering(n_clusters=None,
                                     affinity="precomputed",
                                     linkage=linkage,
                                     distance_threshold=eps)
        labels = Ag.fit_predict(dist)

        c_num = len(set(labels))
        print(c_num)
        # è¿™é‡Œå¯ä»¥åŠ å…¥æ”¹è¿›,inputä¸º
        resdist = cosine_dist + dist
        # é™å™ªç®—æ³•å¼€å§‹
        print("å¼€å§‹é™å™ª")
        n = cosine_dist.shape[0]
        for i in range(n):
          cosine_dist[i][i] == 0
        t_1 = time.time()

        #input:labels and dist, output:redistributed labels
        labels, pecent_dir, Set_merge = denoise_labels_zmh(labels, cosine_dist)

        
        # åˆå¹¶ç±»ä¼¼çš„ç±»
        Set_merge = merge_list(Set_merge)  # åˆå¹¶æœ‰äº¤é›†çš„é›†åˆ
        for i in Set_merge:
            if len(list(i))==0:
              print("æœ‰ç©ºé›†ï¼ï¼ï¼")
            j = list(i)[0]
            labels = [j if x in i else x
                      for x in labels]
        c_num_later = len(np.unique(labels))
        # å¦‚æœèšç±»åæ•°é‡å‡å°‘ï¼Œåˆ™é‡æ–°ç¼–æ’æ ‡ç­¾ä½¿å¾—æ ‡ç­¾å®Œæ•´è€Œä¸ä¼šè®­ç»ƒå‡ºé”™
        unique_label = np.sort(np.unique(labels))
        if c_num_later < c_num:
            for i in range(len(unique_label)):
                label_now = unique_label[i]
                labels = [i if x == label_now else x for x in labels]
        c_num_last = len(np.unique(labels))
        print("èšé¡åç°‡çš„é¡ç‚º{}å€‹".format(c_num_last))
        t_2 = time.time()
        time_denoise = t_2 - t_1
        print("é™å™ªæ—¶é—´ä¸º:{}ç§’".format(time_denoise))
        # é™å™ªç®—æ³•ç»“æŸ

        for fname, label in zip(per_cam_fname[k], labels):
            cluster_results[k][fname] = label
    return cluster_results



##ğŸ“šğŸ“š
def cluster_cross_cam_zmh(cross_cam_dist, features,
                          cross_cam_fname,
                          eph,
                          linkage="average",
                          cams=None,
                          mix_rate=0.,
                          jaccard_sim=None):
    cluster_results = OrderedDict()
    print("Start cluster cross camera according to distance")
    if mix_rate > 0:
        assert jaccard_sim is not None, "if mix_rate > 0, the jaccard sim is needed"
        assert cams is not None, "if mix_rate > 0, the cam is needed"
        n = len(cross_cam_fname)
        cams = np.array(cams).reshape((n, 1))
        expand_cams = np.tile(cams, n)
        mask = np.array(expand_cams != expand_cams.T, dtype=np.float32)
        cross_cam_dist -= mask * jaccard_sim * mix_rate
    cosine_dist = cross_cam_dist
    time1 = time.time()
    cross_cam_dist = re_ranking(cross_cam_dist)
    time2 = time.time()
    print("re_rankingæ—¶é—´ä¸º:{}åˆ†é’Ÿ".format((time2-time1)/60))

    tri_mat = np.triu(cross_cam_dist, 1)
    tri_mat = tri_mat[np.nonzero(tri_mat)]
    tri_mat = np.sort(tri_mat, axis=None)
    top_num = np.round(eph * tri_mat.size).astype(int)
    eps = tri_mat[top_num]
    print(eps)

    Ag = AgglomerativeClustering(n_clusters=None,
                                 affinity="precomputed",
                                 linkage=linkage,
                                 distance_threshold=eps)
    labels = Ag.fit_predict(cross_cam_dist)

    resdist = cosine_dist + cross_cam_dist
    n = resdist.shape[0]
    for i in range(n):
        resdist[i][i] == 0


    time3 = time.time()

    c_num = len(set(labels))
    
    # é™å™ªç®—æ³•å¼€å§‹
    print(c_num)
    print("å¼€å§‹é™å™ª")
    t_1 = time.time()
    # input:labels and dist, output:redistributed labels
    labels, pecent_dir, Set_merge = denoise_labels_zmh(labels, resdist)

    # åˆå¹¶ç±»ä¼¼çš„ç±»
    Set_merge = merge_list(Set_merge)  # åˆå¹¶æœ‰äº¤é›†çš„é›†åˆ
    for i in Set_merge:
        if len(list(i))==0:
          print("æœ‰ç©ºé›†ï¼ï¼ï¼")
        j = list(i)[0]
        labels = [j if x in i else x
                  for x in labels]
    c_num_later = len(np.unique(labels))
    # å¦‚æœèšç±»åæ•°é‡å‡å°‘ï¼Œåˆ™é‡æ–°ç¼–æ’æ ‡ç­¾ä½¿å¾—æ ‡ç­¾å®Œæ•´è€Œä¸ä¼šè®­ç»ƒå‡ºé”™
    unique_label = np.sort(np.unique(labels))
    if c_num_later < c_num:
        for i in range(len(unique_label)):
            label_now = unique_label[i]
            labels = [i if x == label_now else x for x in labels]
    c_num_last = len(np.unique(labels))
    print("èšé¡åç°‡çš„é¡ç‚º{}å€‹".format(c_num_last))
    t_2 = time.time()
    time_denoise = t_2 - t_1
    print("é™å™ªæ—¶é—´ä¸º:{}ç§’".format(time_denoise))
    # é™å™ªç®—æ³•ç»“æŸ
    time4 = time.time()

    print("é™å™ªè€—æ—¶:{}åˆ†é’Ÿ".format((time4-time3)/60))
    print(len(set(labels)))
    for fname, label in zip(cross_cam_fname, labels):
        cluster_results[fname] = label
    return cluster_results


# ğŸ“š our method
def denoise_labels_zmh(labels, dist):  # per_cam_features :[tensor1,tensor2,...,tensor n]

    dir_count = 0
    dir_count_b = 0


    # è®¡ç®—æ¯ç§æ ‡ç­¾å¯¹åº”çš„ç°‡ç‰¹å¾
    label_to_images = {}  # ä¿å­˜æ ‡ç­¾å¯¹åº”ç´¢å¼•ï¼Œç”¨å­—å…¸
    for idx, l in enumerate(labels):
        label_to_images[l] = label_to_images.get(l, []) + [idx]

    # é€šè¿‡reranking_dist å¯»æ‰¾ç°‡ç‰¹å¾
    c_l_index = {}  # ä½œä¸ºç°‡ç‰¹å¾çš„æ ·æœ¬çš„ç´¢å¼•
    c_l = []  # ç°‡ç‰¹å¾å¯¹åº”çš„æ ·æœ¬list
    for l in label_to_images:
        labs = label_to_images[l]  # æ ‡ç­¾å¯¹åº”å›¾åƒçš„idx
        len_labs = len(labs)  # å›¾åƒçš„æ•°é‡
        dist_l = []  # è·ç¦»åˆ—è¡¨
        idx1 = []  # ç´¢å¼•1
        idx2 = []  # ç´¢å¼•2
        if len_labs > 1:
            for i in range((len_labs - 1)):
                for j in range((i + 1), (len_labs)):
                    dist_l.append(dist[labs[i]][labs[j]])
                    idx1.append(labs[i])
                    idx2.append(labs[j])
            sorted_id = sorted(range(len(dist_l)), key=lambda k: dist_l[k], reverse=False)  # Falseä¸ºå‡åºï¼Œè¿™é‡Œçš„å¹³å‡ç‰¹å¾ä¸ºæœ€åƒçš„ç‰¹å¾

            # å°†æœ€è¿‘ä¸¤ä¸ªç‰¹å¾æ±‚å¹³å‡æ–¹æ³•
            # a = sorted_id[0]
            # feature_avg[l] = (pc_f[idx1[a]] + pc_f[idx2[a]]) / 2

            # ä»»æ„æŒ‘é€‰æœ€è¿‘ä¸¤ä¸ªç‰¹å¾çš„å•ç‰¹å¾ä½œä¸ºç°‡ç‰¹å¾æ–¹æ³•
            a = sorted_id[0]
            r = random.random()
            if r > 0.5:
                c_l_index[l] = idx1[a]  # ç°‡ç‰¹å¾çš„ç´¢å¼•
                c_l.append(idx1[a])
            else:
                c_l_index[l] = idx2[a]
                c_l.append(idx2[a])
            # æŒ‡æ•°ä¸ªç‰¹å¾çš„å¹³å‡ç‰¹å¾æ–¹æ³•
            # a = sorted_id[:int(math.log2(len(sorted_id)))]
            # features_sum = torch.FloatTensor(2048)
            # for id in a:
            #     features_sum += (pc_f[idx1[id]] + pc_f[idx2[id]]) / 2
            # feature_avg[l] = features_sum/len(a)

        # å‡å¦‚åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™å°†è¯¥æ ·æœ¬ç‰¹å¾ç›´æ¥è®¾ä¸ºè¯¥ç°‡ç±»ç‰¹å¾
        elif len_labs == 1:
            c_l_index[l] = labs[0]
            c_l.append(labs[0])

    Set_merge = []
    # é¿å…äº’ç›¸ç›¸ä¼¼çš„æ ·æœ¬è¢«äº’ç›¸åˆ†é…è€Œè¾¾ä¸åˆ°åˆ†é…åˆ°ä¸€èµ·çš„æ•ˆæœ caous_void
    caous_void = {}
    for l in range(len(np.unique(labels))):  # éå†æ¯ä¸ªç±»
        indexs_features = label_to_images[l]
        P = []
        len_c = len(np.unique(labels))  # ç±»æ•°

        # åŸºäºdistè®¡ç®—æ ·æœ¬å¹²å‡€æ¦‚ç‡  in:æ ·æœ¬çš„ç´¢å¼•  out:æ ·æœ¬çš„å¹²å‡€æ¦‚ç‡
        sample_index = c_l_index[l]  # å½“å‰éå†ç±»åˆ«çš„ç°‡ç‰¹å¾å¯¹åº”æ ·æœ¬çš„ç´¢å¼•
        Index_P = []

        for i in indexs_features:
            a = []
            label_a = []
            dict_dist = {}
            Temp_merge = []
            for j in c_l:  # ä¼˜å…ˆå°†æ ·æœ¬iè·Ÿlå¯¹åº”æ ·æœ¬çš„è·ç¦»åŠ åˆ°å­—å…¸
                if labels[j] == l:
                    dict_dist[l] = dist[i][j]
                    break
            for j in c_l:
                a.append(dist[i][j])
                label_a.append(labels[j]) #æ¯ä¸ªè·ç¦»å¯¹åº”çš„æ ‡ç­¾
                if labels[j] == l:  # å¦‚æœå†æ¬¡é‡åˆ°lå¯¹åº”æ ·æœ¬ï¼Œåˆ™è·³è¿‡ï¼Œå› ä¸ºå­—å…¸é‡Œå·²ç»å­˜åœ¨äº†iä¸lçš„è·ç¦»
                    continue
                dict_dist[j] = dist[i][j]
            a.append(dist[i][sample_index])  # æ‹¼æ¥ï¼Œæ­¤æ—¶æœ‰c+1ä¸ªç›¸ä¼¼åº¦
            sorted_id = sorted(range(len_c + 1), key=lambda k: a[k], reverse=False)  # å‡åºæ’åº
            b = sorted_id.index(len_c) + 1  # è·å¾—è¯¥ç±»ç›¸ä¼¼åº¦åœ¨c+1ä¸ªä¸­çš„æ’ä½
            #å¦‚æœiä¸å¾ˆå¤šç°‡ç±»è·ç¦»ç›¸ç­‰ï¼Œåˆ™æŠŠç›¸ç­‰çš„ç±»éƒ½åˆå¹¶ï¼è¦åˆå¹¶çš„ç±»æ ‡è®°å‡ºæ¥,å‡ºå»ä¹‹åå†åˆå¹¶ã€‚æ­£å¸¸æ¥è¯´è‹¥iæœ€åƒlï¼Œåˆ™båº”è¯¥ç­‰äº2
            if b > 2 and a[sorted_id[0]] == a[len_c]: #è¿™æ˜¯è¯´æ˜å­˜åœ¨å…¶ä»–ç±»ä¸içš„è·ç¦»å’Œlä¸içš„ä¸€æ ·ï¼
                print("å‡ºç°æ ·æœ¬iä¸{}ä¸ªç°‡ç‰¹å¾ä¸€æ ·æœ€ç›¸ä¼¼ï¼".format(b-1))
                for i in range(b-1):
                    Temp_merge.append(label_a[sorted_id[i]])    #å°†æ’åœ¨å‰é¢ç›¸åŒè·ç¦»çš„ç°‡ç±»æ ‡ç­¾è®°ä½åœ¨Temp_merge
                Set_merge.append(set(Temp_merge))
            P = P + [b]
            #æœ€åƒä¸€ç±»çš„ç°‡æ ·æœ¬ç´¢å¼•
            c = min(dict_dist, key=dict_dist.get)
            Index_P.append(labels[c]) #å°†æ’ä½ç¬¬ä¸€çš„ç±»çš„ç´¢å¼•èµ‹ç»™Index_P

        # ç›¸ä¼¼åº¦æ’ä½é˜ˆå€¼
        # threshold = 1.00 / (len_c + 1)
        threshold = 2
        for i, j, ll in zip(indexs_features, P, Index_P):  # å¯¹è¯¥ç±»çš„æ¯ä¸ªæ ·æœ¬çš„ç´¢å¼•iåŠå…¶å¯¹åº”ç‰¹å¾çš„å¹²å‡€æ¦‚ç‡
            if j > threshold:
                # åˆ¤æ–­æ˜¯å¦llå¯¹åº”çš„æ ·æœ¬å·²ç»åˆ†é…å…¶å™ªå£°æ•°æ®åˆ°æ­¤ï¼Œè‹¥æœ‰åˆ™ä¸éœ€è¦å†å°†æ­¤å¤„çš„å™ªå£°æ•°æ®åˆ†é…è¿‡å»
                if labels[i] in caous_void:
                    if ll in caous_void[labels[i]]:
                        dir_count_b += 1
                        continue
                if ll not in caous_void:
                    caous_void[ll] = [labels[i]]
                else:
                    caous_void[ll].append(labels[i])
                labels[i] = ll
                dir_count += 1
    pecent_dir = (dir_count + dir_count_b) / len(labels)
    print("ç­›é”™æ¯”ä¾‹ä¸ºï¼š{:.2%},å…±æœ‰{}å¼ è¢«ç­›é”™,å…¶ä¸­æœ‰{}å¼ äº’ç›¸åˆ†é…ã€‚".format(pecent_dir, dir_count, dir_count_b))
    return labels, pecent_dir, Set_merge




def get_intra_cam_cluster_result(model, data_loader, eph, linkage):
    per_cam_features, per_cam_fname = extract_features_per_cam(
        model, data_loader)

    per_cam_dist = distane_per_cam(per_cam_features)

    # åŸè®ºæ–‡æ–¹æ³•
    cluster_results = cluster_per_cam(per_cam_dist, per_cam_fname, eph, linkage)
    # æ”¹è¿›æ–¹æ³•
    # æ‰“å°æ¯ä¸ªæ‘„åƒæœºçš„æ ·æœ¬
    # len_camera = len(per_cam_dist)
    # for i in range(len_camera):
    #     print("æ‘„åƒæœº:{}çš„æ ·æœ¬æ•°ä¸º{}ä¸ª".format(i, len(per_cam_features[i])))
    # cluster_results = cluster_per_cam_zmh(per_cam_dist, per_cam_fname, eph, linkage)

    return cluster_results


def get_inter_cam_cluster_result(model,
                                 data_loader,
                                 eph,
                                 linkage,
                                 mix_rate=0., use_cpu=False):
    features, fnames, cross_cam_distribute, cams = extract_features_cross_cam(
        model, data_loader)

    cross_cam_distribute = torch.Tensor(np.array(cross_cam_distribute)).cuda()
    cross_cam_dist = distance_cross_cam(features, use_cpu=use_cpu)

    t1 = time.time()
    if mix_rate > 0:
        jaccard_sim = jaccard_sim_cross_cam(cross_cam_distribute)
    else:
        jaccard_sim = None
    t2 = time.time()
    ttt = t2-t1
    print("è®¡ç®—jaccardç›¸ä¼¼åº¦çš„æ—¶é—´:{}ç§’".format(ttt))
    # åŸæ–‡ç®—æ³•
    cluster_results = cluster_cross_cam(cross_cam_dist,
                                        fnames,
                                        eph,
                                        linkage=linkage,
                                        cams=cams,
                                        mix_rate=mix_rate,
                                        jaccard_sim=jaccard_sim,
                                        )

    # æ”¹è¿›ç®—æ³• with our method

    # cluster_results = cluster_cross_cam_zmh(cross_cam_dist,features,
    #                                     fnames,
    #                                     eph,
    #                                     linkage=linkage,
    #                                     cams=cams,
    #                                     mix_rate=mix_rate,
    #                                     jaccard_sim=jaccard_sim,
    #                                     )
    return cluster_results
